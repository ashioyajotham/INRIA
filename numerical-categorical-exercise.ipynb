{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-02T15:21:25.265250Z","iopub.execute_input":"2022-04-02T15:21:25.266077Z","iopub.status.idle":"2022-04-02T15:21:25.298879Z","shell.execute_reply.started":"2022-04-02T15:21:25.265956Z","shell.execute_reply":"2022-04-02T15:21:25.298101Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/adultcensus/adult-census.csv\n/kaggle/input/adultcensus/adult-census-numeric-test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\nadult_census = pd.read_csv(\"../input/adultcensus/adult-census.csv\")\n\ntarget_name = \"class\"\ntarget = adult_census[target_name]\ndata = adult_census.drop(columns=[target_name, \"education-num\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-02T15:23:49.247695Z","iopub.execute_input":"2022-04-02T15:23:49.247966Z","iopub.status.idle":"2022-04-02T15:23:49.398356Z","shell.execute_reply.started":"2022-04-02T15:23:49.247937Z","shell.execute_reply":"2022-04-02T15:23:49.397646Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import make_column_selector as selector\n\nnumerical_columns_selector = selector(dtype_exclude=object)\ncategorical_columns_selector = selector(dtype_include=object)\nnumerical_columns = numerical_columns_selector(data)\ncategorical_columns = categorical_columns_selector(data)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T15:24:13.301166Z","iopub.execute_input":"2022-04-02T15:24:13.301465Z","iopub.status.idle":"2022-04-02T15:24:14.225704Z","shell.execute_reply.started":"2022-04-02T15:24:13.301421Z","shell.execute_reply":"2022-04-02T15:24:14.224914Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import time\n\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\ncategorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n                                          unknown_value=-1)\npreprocessor = ColumnTransformer([\n    ('categorical', categorical_preprocessor, categorical_columns)],\n    remainder=\"passthrough\")\n\nmodel = make_pipeline(preprocessor, HistGradientBoostingClassifier())\n\nstart = time.time()\ncv_results = cross_validate(model, data, target)\nelapsed_time = time.time() - start\n\nscores = cv_results[\"test_score\"]\n\nprint(\"The mean cross-validation accuracy is: \"\n      f\"{scores.mean():.3f} +/- {scores.std():.3f} \"\n      f\"with a fitting time of {elapsed_time:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-02T15:24:44.321991Z","iopub.execute_input":"2022-04-02T15:24:44.322242Z","iopub.status.idle":"2022-04-02T15:24:50.763985Z","shell.execute_reply.started":"2022-04-02T15:24:44.322215Z","shell.execute_reply":"2022-04-02T15:24:50.763259Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"The mean cross-validation accuracy is: 0.873 +/- 0.002 with a fitting time of 6.213\n","output_type":"stream"}]},{"cell_type":"code","source":"# scaling \nimport time\n\nfrom sklearn.preprocessing import StandardScaler\n\npreprocessor = ColumnTransformer([\n    ('numerical', StandardScaler(), numerical_columns),\n    ('categorical', OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n                                   unknown_value=-1),\n     categorical_columns)])\n\nmodel = make_pipeline(preprocessor, HistGradientBoostingClassifier())\n\nstart = time.time()\ncv_results = cross_validate(model, data, target)\nelapsed_time = time.time() - start\n\nscores = cv_results[\"test_score\"]\n\nprint(\"The mean cross-validation accuracy is: \"\n      f\"{scores.mean():.3f} +/- {scores.std():.3f} \"\n      f\"with a fitting time of {elapsed_time:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-02T15:25:16.836742Z","iopub.execute_input":"2022-04-02T15:25:16.837021Z","iopub.status.idle":"2022-04-02T15:25:23.348826Z","shell.execute_reply.started":"2022-04-02T15:25:16.836985Z","shell.execute_reply":"2022-04-02T15:25:23.348063Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The mean cross-validation accuracy is: 0.873 +/- 0.003 with a fitting time of 6.505\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* Scaling numerical features is indeed useless for most decision tree models in general and \n  for `HistGradientBoostingClassifier` in particular.","metadata":{}},{"cell_type":"code","source":"import time\n\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\npreprocessor = ColumnTransformer([\n    ('one-hot-encoder', categorical_preprocessor, categorical_columns)],\n    remainder=\"passthrough\")\n\nmodel = make_pipeline(preprocessor, HistGradientBoostingClassifier())\n\nstart = time.time()\ncv_results = cross_validate(model, data, target)\nelapsed_time = time.time() - start\n\nscores = cv_results[\"test_score\"]\n\nprint(\"The mean cross-validation accuracy is: \"\n      f\"{scores.mean():.3f} +/- {scores.std():.3f} \"\n      f\"with a fitting time of {elapsed_time:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-02T15:28:00.893938Z","iopub.execute_input":"2022-04-02T15:28:00.894207Z","iopub.status.idle":"2022-04-02T15:28:16.945713Z","shell.execute_reply.started":"2022-04-02T15:28:00.894177Z","shell.execute_reply":"2022-04-02T15:28:16.944086Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The mean cross-validation accuracy is: 0.874 +/- 0.002 with a fitting time of 16.044\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* `OneHotEncoder`: will always do something meaningful, but can be unnecessary slow with trees.\n\n* `OrdinalEncoder`: can be detrimental for linear models unless your category has a meaningful order and you make sure that OrdinalEncoder respects this order. Trees can deal with OrdinalEncoder fine as long as they are deep enough.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}